# Spur AI Support Chat

A production-minded AI-powered customer support chat application built as part of the **Spur Software Engineer assignment**.

This project simulates a realistic AI support agent for a small e-commerce store, with a strong focus on **clean architecture, robustness, correctness, and UX polish**.

---

## ‚ú® Features

- End-to-end chat experience (Frontend + Backend)
- Session-based conversations
- Persistent message storage
- Real LLM integration (Groq ‚Äì LLaMA 3.1)
- Graceful error handling
- Typing indicator with realistic typing effect
- Clean, readable, idiomatic TypeScript codebase

---

## üß± Architecture Overview

### High-Level Flow

React Frontend (Vite)
‚Üì
POST /chat/message
‚Üì
Chat Route (validation + orchestration)
‚Üì
Chat Service (DB persistence + history)
‚Üì
LLM Service (Groq LLaMA 3.1)
‚Üì
Persist AI reply ‚Üí return response

yaml
Copy code

The backend is intentionally **stateless** ‚Äî conversation context is reconstructed from the database on every request.  
This makes the system predictable, easy to reason about, and easy to extend to additional channels (WhatsApp, Instagram, etc.).

---

## üìÅ Backend Structure (TypeScript + Node.js)
```
backend
‚îú‚îÄ‚îÄ prisma
‚îÇ   ‚îî‚îÄ‚îÄ schema.prisma
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îú‚îÄ‚îÄ db
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prisma.ts
‚îÇ   ‚îú‚îÄ‚îÄ routes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat.route.ts
‚îÇ   ‚îú‚îÄ‚îÄ services
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.service.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm.service.ts
‚îÇ   ‚îî‚îÄ‚îÄ server.ts
‚îî‚îÄ‚îÄ package.json
```

### Key Design Decisions

- Routes handle **only HTTP concerns**
- Services contain **business logic**
- LLM integration is **isolated behind a single service**
- Prisma ORM ensures **clean, type-safe database access**

---

## üñ• Frontend Structure (React + TypeScript + Vite)

- Single chat window UI
- Clear distinction between user and AI messages
- Auto-scroll to latest message
- Enter-to-send support
- Disabled input while request is in flight
- Typing indicator with character-by-character AI response simulation

The typing effect avoids the ‚Äúinstant AI response‚Äù feel and makes the interaction closer to a real support agent.

---

## üóÑ Data Model & Persistence

### Conversations
- `id`
- `createdAt`

### Messages
- `id`
- `conversationId`
- `sender` (`user` | `ai`)
- `text`
- `createdAt`

Every user and AI message is persisted.  
Conversation context is reconstructed from the database on each request.

---

## üöÄ Running Locally (Step-by-Step)

### 1Ô∏è‚É£ Clone the Repository

git clone https://github.com/ratishoberoi/spur-ai-chat.git
cd spur-ai-chat

yaml
Copy code

---

### 2Ô∏è‚É£ Backend Setup

cd backend
npm install

markdown
Copy code

#### Configure Environment Variables

Create a `.env` file inside the `backend` directory:

type nul > .env

pgsql
Copy code

Add the following to `.env`:

GROQ_API_KEY=your_groq_api_key_here
DATABASE_URL=file:./dev.db

yaml
Copy code

---

### 3Ô∏è‚É£ Database Setup (Prisma)

Run migrations:

npx prisma migrate dev

yaml
Copy code

This will:
- Apply schema migrations
- Create the SQLite database (`dev.db`)
- Generate the Prisma client

---

### 4Ô∏è‚É£ Start the Backend

npm run dev

powershell
Copy code

Backend will start at:

http://localhost:4000

yaml
Copy code

---

### 5Ô∏è‚É£ Frontend Setup

Open a **new terminal window**, then run:

cd frontend
npm install
npm run dev

powershell
Copy code

Frontend will start at:

http://localhost:5173

yaml
Copy code

You can now chat end-to-end locally.

---

## üîå Backend API Endpoints (Verification & Testing)

The backend is an **API-only service** and does not expose a root (`/`) page.

If you open:

https://spur-ai-chat-backend-r7hv.onrender.com/

yaml
Copy code

You will see:

Cannot GET /

yaml
Copy code

This is expected behavior.

---

### 1Ô∏è‚É£ Health Check Endpoint

**URL**
GET /health

markdown
Copy code

**Example**
https://spur-ai-chat-backend-r7hv.onrender.com/health

markdown
Copy code

**Response**
{
"status": "ok",
"service": "spur-ai-chat-backend"
}

yaml
Copy code

---

### 2Ô∏è‚É£ Chat Message Endpoint (Core API)

**URL**
POST /chat/message

markdown
Copy code

**Example**
https://spur-ai-chat-backend-r7hv.onrender.com/chat/message

css
Copy code

**Request Body**
{
"message": "What is your return policy?"
}

markdown
Copy code

**Response**
{
"reply": "We offer a 7-day no-questions-asked return policy...",
"conversationId": "generated-conversation-id"
}

yaml
Copy code

- `conversationId` can be reused to continue the same conversation
- All user and AI messages are persisted

---

### 3Ô∏è‚É£ Manual API Testing (Optional)

curl -X POST https://spur-ai-chat-backend-r7hv.onrender.com/chat/message
-H "Content-Type: application/json"
-d '{"message":"Do you ship to USA?"}'

yaml
Copy code

---

## ü§ñ LLM Integration Notes

- **Provider:** Groq
- **Model:** LLaMA 3.1 (8B)
- **Why Groq?**
  - Free tier available
  - Very low latency
  - OpenAI-compatible API

### Prompting Strategy

- System prompt defines the agent as a helpful e-commerce support agent
- Store policies (shipping, returns, support hours) are embedded directly
- Recent conversation history is included for contextual replies
- History length is capped to control cost and latency

---

## üõ° Robustness & Error Handling

- Empty messages are rejected
- Backend never crashes on invalid input
- LLM/API failures are caught and surfaced as friendly user-facing errors
- Frontend disables input during in-flight requests
- No secrets are committed to the repository

Graceful failure is always preferred over silent failure.

---

## ‚öñ Trade-offs & Future Improvements

### Trade-offs

- SQLite chosen for simplicity and portability
- Prompt-based FAQ knowledge instead of a vector database

### If I Had More Time‚Ä¶

- Add vector search for dynamic FAQs
- Reload conversation history on page refresh
- Stream LLM responses instead of simulated typing
- Add basic analytics (latency, error rates)
- Improve accessibility and theming

---

## üåç Deployment

- **Frontend (Vercel):**  
  https://spur-ai-chat.vercel.app

- **Backend (Render):**  
  https://spur-ai-chat-backend-r7hv.onrender.com
